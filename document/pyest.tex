\documentclass[12pt,preprint]{aastex}
\usepackage{amssymb,amsmath}

\newcommand{\project}[1]{\texttt{#1}}
\newcommand{\this}{\project{PyEST}}
\newcommand{\foreign}[1]{\emph{#1}}
\newcommand{\etal}{\foreign{et\,al.}}
\newcommand{\etc}{\foreign{etc.}}

\newcommand{\fig}[1]{Figure \ref{fig:#1}}
\newcommand{\figlabel}[1]{\label{fig:#1}}
\newcommand{\Eq}[1]{Equation (\ref{eq:#1})}
\newcommand{\eq}[1]{equation (\ref{eq:#1})}
\newcommand{\eqlabel}[1]{\label{eq:#1}}

% math symbols
\newcommand{\dd}{\mathrm{d}}
\newcommand{\like}{\mathscr{L}}
\newcommand{\bvec}[1]{\boldsymbol{#1}}
\newcommand{\normal}[3]{\mathcal{N} (#1 | #2, #3)}

% model parameters
\newcommand{\model}{\paramvector{\Theta}}
\newcommand{\data}{\paramvector{X}}

% units
\newcommand{\unit}[1]{\mathrm{#1}}

\begin{document}

\title{PyEST: Python Ensemble Sampling Toolkit}
\author{Daniel~Foreman-Mackey}
\affil{Center for Cosmology and Particle Physics,
                         Department of Physics, New York University,
                         4 Washington Place, New York, NY, 10003, USA; danfm@nyu.edu}

\begin{abstract}

    Markov chain Monte Carlo (MCMC) has proven to be a powerful tool for Bayesian
    parameter estimation in many applications in astronomy and cosmology.  Most
    standard MCMC algorithms require fine-tuning of the proposal distribution
    through a computationally expensive ``burn-in'' phase --- especially when the
    sampled distribution is highly covariant.
    Affine invariant ensemble samplers don't face this problem and they generally
    converge with fewer steps in the chain.

    I present a generalization to the \citet{Goodman:2010} affine invariant sampler
    that allows for arbitrarily sophisticated unsupervised machine learning techniques
    to be used to generate the proposal distribution.  I show that even a very simple
    application of our algorithm is extremely efficient.  I judge the efficiency
    of the algorithm based on the autocorrelation time of many chains.

    This result is particularly useful in situations where the likelihood call is
    very computationally expensive so that the extra cost associated with generating
    the proposal is outweighed by the reduction in autocorrelation time.

\end{abstract}

\keywords{
}

\section{Introduction}

\begin{enumerate}

    \item Bayesian inference  --- and with it, MCMC sampling --- is becoming an
        integral part of the day-to-day routine for many astronomers (tons of
        citations). and "why you might want to join the ranks of these kool kids;
        it's not hard, and you don't have to drink the kool-aid to be Bayesian
        when necessary." Remember, a maximum-likelihood problem can be rephrased
        as an MCMC problem easily by assuming flat priors.

    \item Traditional sampling methods (M-H) become extremely inefficient as the
        underlying distribution becomes non-Gaussian or even just highly covariant.
        There have been various ad-hoc fine-tuning methods proposed to deal with
        this problem (citations; annealing, proposal covariance estimation, etc.)
        and various more sophisticated methods (?; e.g.~Nested sampling, etc.;
        citations) but these modifications are often difficult to implement and
        require significant fine-tuning of free parameters to obtain an efficient
        sampling.

    \item Cite Goodman \& Weare and give a quick summary of why it's good.

    \item Cite Hou \etal, Lang \& Hogg and any other applications.

\end{enumerate}

\section{The Algorithm}

\citet{Hou:2011}

At the core of \this, lies the affine invariant ensemble sampler from
\citep{Goodman:2010}.  In particular, I have implemented the ``stretch move''
algorithm.  To achieve convergence with standard MCMC samplers, several
hyperparameters must be fine tuned to account for non-trivial covariances between
the model parameters of a particular problem \citep[e.g.][]{Dunkley:2005}.
The performance of an affine invariant sampler, however, is independent of the
off-diagonal terms in the covariance matrix of any specific distribution.

\subsection{The stretch move}

\citet{Goodman:2010} proposed an affine invariant ensemble sampling algorithm
informally called the ``stretch move''. This method involves simultaneously
evolving an ensemble of $K$ \emph{walkers} where the proposal distribution for one
walker $k$ is based on the current positions of the $K-1$ walkers in the
\emph{complementary ensemble}.

In practice, to update the position of a walker at position $\mathbf{X}_k$,
another walker $\mathbf{X}_j$ with $j \ne k$ is randomly chosen and then
a new position is proposed:
\begin{equation}
    \eqlabel{proposal}
    \mathbf{X}_k (t) \rightarrow \mathbf{Y} = \mathbf{X}_j + Z \, [\mathbf{X}_k (t) - \mathbf{X}_j]
\end{equation}
where $Z$ is a random variable drawn from a distribution $g(z)$.  It is clear that
if $g(z)$ satisfies
\begin{equation}
    g(z^{-1}) = z \, g(z),
\end{equation}
the proposal of \eq{proposal} is symmetric. In this case, the chain will satisfy
detailed balance if the proposal is accepted with probability
\begin{equation}
    \min \left \{ 1, Z^{n-1} \, \frac{p(\mathbf{Y})}{p(\mathbf{X}_k(t))} \right \}.
\end{equation}
This procedure is then repeated for each walker in the ensemble \emph{in series}.

\citet{Goodman:2010} advocate for a particular form of $g(z)$, namely
\begin{equation}
    g(z) \propto \left \{ \begin{array}{ll}
        \displaystyle\frac{1}{\sqrt{z}} & \mathrm{if}\, z\in \left [ \displaystyle\frac{1}{a}, a \right ], \\
        0 & \mathrm{otherwise}
    \end{array} \right .
\end{equation}
where $a$ is an adjustable scale parameter. For comparison, I will also use this
distribution with $a=2$ for all benchmarks in this paper.

\subsection{The parallel stretch move}

It is tempting to na\"ively parallelize the stretch move algorithm by simultaneously
advancing each walker based on the state of the ensemble instead of evolving the
walkers in series. Unfortunately, this would no longer satisfy detailed balance.
Instead, if we split the ensemble into two ensembles (labeled \emph{blue} and
\emph{red} for convenience) and simultaneously update all the blue walkers ---
using the stretch move procedure --- based on the positions of \emph{only the red
walkers} then the outcome is a valid step for each of the walkers. Then,
the red walkers are advanced based only on the positions in the blue ensemble.

The performance of this method --- quantified by the autocorrelation time --- is
comparable to the traditional stretch move algorithm but the fact that one can now
take advantage of generic parallelization makes this generalization extremely
powerful.

\subsection{Using machine learning to generate a better proposal distribution}

The proposal distribution given by \eq{proposal} can be visualized as fitting a
multi-dimensional Gaussian to the positions in the complementary ensemble,
doubling the eigenvalues of the covariance tensor and resampling from that
distribution. In fact, as one would expect, this scheme gives slightly better
performance when sampling from a multi-dimensional, highly covariant Gaussian
(described below). This realization makes it interesting to explore the possibility
of using more sophisticated machine learning techniques to provide a better proposal
distribution.

\subsubsection{The single Gaussian proposal}

The simplest extension is (as mentioned above) the single Gaussian proposal. Given
two ensembles $E_\mathrm{red} = \{ \mathbf{X}_1, \mathbf{X}_2, \ldots, \mathbf{X}_{K/2} \}$
and $E_\mathrm{blue} = \{ \mathbf{X}_{K/2+1}, \ldots, \mathbf{X}_{K} \}$, a single step
in the chain will involve:
\begin{enumerate}
    \item{
        Calculate the mean position $\bar{\mathbf{X}}_\mathrm{blue} = \frac{2}{K}\sum_{k=K/2+1} ^K \mathbf{X}_k$
        and covariance tensor $\mathcal{C}_\mathrm{blue}$ for the \emph{blue} walkers.
        }
    \item{
        Sample $K/2$ random vectors $\mathbf{Y}_k$ from the multivariate Gaussian distribution
        \begin{equation}
            \eqlabel{singlegaussprop}
            f(\mathbf{y}) = [2 \pi]^{-K/4} \left | \mathcal{C} \right |^{-1/2}
            \exp \left ( -\frac{1}{2} [\mathbf{y} - \bar{\mathbf{X}}_\mathrm{blue}]^\mathrm{T}
            \mathcal{C}^{-1} [\mathbf{y} - \bar{\mathbf{X}}_\mathrm{blue}] \right )
        \end{equation}
        }
    \item{
        Accept each proposed position with the probability
        \begin{equation}
            \eqlabel{singlegaussaccept}
            \min \left \{ 1, \frac{f(\mathbf{X}_k(t)) \, p(\mathbf{Y}_k)}{f(\mathbf{Y}_k) \, p(\mathbf{X}_k(t))} \right \}
        \end{equation}
        and set the positions of the \emph{red} walkers to either $\mathbf{X}_k (t+1) = \mathbf{X}_k(t)$
        if the proposal is rejected
        or $\mathbf{X}_k (t+1) = \mathbf{Y}_k$ if the step is accepted.
        }
    \item{
        Repeat steps 1-3 with the red and blue ensembles switched.
        }
\end{enumerate}

\subsubsection{The mixture of Gaussians proposal}

\Eq{singlegaussprop} above can be replaced by a mixture of Gaussians and it can
be trained using EM or a similar algorithm. In this case, the algorithm is
as follows:
\begin{enumerate}
    \item{
        Run K-means (with $K=M$ is a free parameter of the sampler) on the blue
        walkers to initialize the EM algorithm, run EM
        to convergence (or stop early as discussed later) to find the amplitudes
        $\alpha_j$, the means $\boldsymbol{\mu}_j$ and covariances $\Sigma_j$ of the Gaussians.
        }
    \item{
        Sample $K/2$ vectors from
        \begin{equation}
            f(\mathbf{y}) = [2 \pi]^{-K/4} \sum _{j=1} ^{M} \alpha_j \, \left | \Sigma_j \right |^{-1/2} \,
            \exp \left ( -\frac{1}{2} [\mathbf{y} - \boldsymbol{\mu}_j]^\mathrm{T}
            \Sigma_j^{-1} [\mathbf{y} - \boldsymbol{\mu}_j] \right )
        \end{equation}
        }
    \item{
        Accept the proposed positions with the probability given by \eq{singlegaussaccept}.
        }
\end{enumerate}

The major problem with this algorithm is that the K-means algorithm is not affine
invariant.  Instead, I generalized the K-means algorithm to work with any arbitrary
metric (not just Euclidean).  If the covariance tensor of the samples is used as
the metric then the algorithm is affine invariant.  I will study the performance of
both of these algorithms below.

\subsubsection{The mixture of Laplacians proposal}

I did not implement the mixture of Laplacians proposal distribution for this paper
but it should be a simple extension of the mixture of Gaussians model. Laplacians
are advantageous because they have ``heavier tails''. This will improve the sampling
performance in the tails of the target density. The mixture of Gaussians has very weak
support in the tails so walkers tend to get ``stuck'' in the tails of the distribution.

\section{Benchmarks \& Tests}

\subsection{Measuring the performance}

A standard method of quantifying the performance of an MCMC sampler is to estimate
the autocorrelation time of the sampler on several densities.

The main goal of running a Markov chain is to measure the expectation value (and
variance) of a particular value (e.g.~$f$)
\begin{equation}
    \left < f(\mathbf{x}) \right > = \int f(\mathbf{x}) \, p (\mathbf{x}) \, \dd \mathbf{x}
\end{equation}
which can be approximated as
\begin{equation}
    \eqlabel{schainestim}
    \left < f(\mathbf{x}) \right > \approx \frac{1}{T_s} \sum_{t=1}^{T_s} f(\mathbf{X}(t))
\end{equation}
where $T$ is the length of the chain.  The generalization of \eq{schainestim} to
the case of the ensemble sampler is
\begin{equation}
    \eqlabel{echainestim}
    \left < f(\mathbf{x}) \right > \approx \frac{1}{T_e} \sum_{t=1}^{T_s} \left [ \frac{1}{K} \sum_{k = 1}^{K} f(\mathbf{X}_k(t)) \right ]
\end{equation}
where $K$ is the number of walkers.  The autocorrelation function of the chain is
then given by
\begin{equation}
    C (t) = \frac{1}{K^2} \lim_{t^\prime \to \infty} \mathrm{cov} \left [ \sum_{k = 1}^{K} f(\mathbf{X}_k (t+t^\prime)),
         \sum_{k = 1}^{K} f(\mathbf{X}_k (t^\prime)) \right ]
\end{equation}
and the integrated autocorrelation time is given by
\begin{equation}
    \tau = \sum_{t= -\infty} ^{\infty} \frac{C(t)}{C(0)} .
\end{equation}

For all tests discussed in this paper, I have used the \project{pyacor}\footnote{\texttt{https://github.com/dfm/acor}}
module to estimate the autocorrelation time of the chains. I ported \project{pyacor} to \project{Python}
from the original \project{C++} procedure that is described in \citet{Goodman:2010} and
is available online\footnote{\texttt{http://www.math.nyu.edu/faculty/goodman/software/acor/index.html}}

\section{Our Implementation}

\begin{enumerate}

    \item Why Python?

    \item ``Checkerboard'' stepping instead of sequential in order to parallelize

    \item Sample code

    \item Access, license, etc.

\end{enumerate}

\section{Numerical Tests}

\begin{enumerate}

    \item Outline a basic M-H algorithm as the baseline comparison

    \item Introduce autocorrelation time as an analytic for convergence testing.

    \item Tests:
        \begin{itemize}
            \item \emph{N}-Gaussian (if proposal distribution isn't chosen properly
                M-H is slow but it's fine if the proposal distribution is right).
                \this~destroys this problem no matter what!

            \item Rosenbrock density (highly non-Gaussian) --- \emph{epic} failure
                for M-H but \this~does well.

            \item Multimodal distribution?

            \item Fitting a line?

            \item Others?
        \end{itemize}

\end{enumerate}

\section{Discussion}

\begin{enumerate}

    \item Discuss specific applications of the algorithm in astronomy (Hou \etal;
        Hogg \& Lang; DFM \& Widrow; \etc)

    \item Convince everybody that they should use it and cite us\ldots

\end{enumerate}

\begin{thebibliography}{70}
\raggedright

\bibitem[Dunkley \etal(2005)]{Dunkley:2005}
{Dunkley}, J., {Bucher}, M., {Ferreira}, P.~G., {Moodley}, K., \& {Skordis}, C.,
2005, \mnras, 356, 925-936
% http://adsabs.harvard.edu/abs/2005MNRAS.356..925D

\bibitem[Goodman \& Weare~(2010)]{Goodman:2010}
Goodman,~J., \& Weare,~J.,
2010, Comm.\ App.\ Math.\ Comp.\ Sci., 5, 65

\bibitem[F. Hou \etal(2011))]{Hou:2011}
{Hou}, F., {Goodman}, J., {Hogg}, D.~W., {Weare}, J., \& {Schwab}, C.,
2011, arXiv:1104.2612
% http://adsabs.harvard.edu/abs/2011arXiv1104.2612H

\end{thebibliography}


\end{document}



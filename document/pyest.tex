\documentclass[12pt,preprint]{aastex}
\usepackage{amssymb,amsmath}

\newcommand{\project}[1]{\texttt{#1}}
\newcommand{\this}{\project{PyEST}}
\newcommand{\foreign}[1]{\emph{#1}}
\newcommand{\etal}{\foreign{et\,al.}}
\newcommand{\etc}{\foreign{etc.}}

\newcommand{\Fig}[1]{Figure \ref{fig:#1}}
\newcommand{\fig}[1]{figure \ref{fig:#1}}
\newcommand{\figlabel}[1]{\label{fig:#1}}
\newcommand{\Tab}[1]{Table \ref{tab:#1}}
\newcommand{\tab}[1]{table \ref{tab:#1}}
\newcommand{\tablabel}[1]{\label{tab:#1}}
\newcommand{\Eq}[1]{Equation (\ref{eq:#1})}
\newcommand{\eq}[1]{equation (\ref{eq:#1})}
\newcommand{\eqlabel}[1]{\label{eq:#1}}

% math symbols
\newcommand{\dd}{\mathrm{d}}
\newcommand{\like}{\mathscr{L}}
\newcommand{\bvec}[1]{\boldsymbol{#1}}
\newcommand{\normal}[3]{\mathcal{N} (#1 | #2, #3)}

% model parameters
\newcommand{\model}{\paramvector{\Theta}}
\newcommand{\data}{\paramvector{X}}

% units
\newcommand{\unit}[1]{\mathrm{#1}}

\begin{document}

\title{PyEST: Python Ensemble Sampling Toolkit}
\author{Daniel~Foreman-Mackey}
\affil{Center for Cosmology and Particle Physics,
                         Department of Physics, New York University,
                         4 Washington Place, New York, NY, 10003, USA; danfm@nyu.edu}

\begin{abstract}

    Markov chain Monte Carlo (MCMC) has proven to be a powerful tool for Bayesian
    parameter estimation in many applications in astronomy and cosmology.  Most
    standard MCMC algorithms require fine-tuning of the proposal distribution
    through a computationally expensive ``burn-in'' phase --- especially when the
    sampled distribution is highly covariant.
    Affine invariant ensemble samplers don't face this problem and they generally
    converge with fewer steps in the chain.

    I present a generalization to the \citet{Goodman:2010} affine invariant sampler
    that (a) provides automatic parallelization of the algorithm and (b) allows
    for arbitrarily sophisticated unsupervised machine learning techniques
    to be used to generate the proposal distribution.  I show that even a simple
    application of the algorithm is efficient.  I judge the efficiency
    of the algorithm based on the autocorrelation time of the samplers on two
    test densities.

    This result is particularly useful in situations where the likelihood call is
    very computationally expensive so that the extra cost associated with generating
    the proposal is outweighed by the reduction in autocorrelation time.

\end{abstract}

\keywords{
    methods: data analysis ---
    methods: numerical ---
    methods: statistical
}

\section{Introduction}

In recent years, the astronomy and cosmology literature has been full of articles
promoting Bayesian methods of data analysis. Bayesian inference is particularly
relevant in astrophysics because most problems are being solved in the regime of
very low signal-to-noise, large systematic uncertainties and missing components of
the data. These problems might seem like serious road blocks. In most physics problems
of interest, however, there is generally a motivated, physical generative model
that makes predictions about the data or several such models that we wish to compare.
If we can leverage the physics that we understand and the rich prior information
from the literature then there is a chance --- it has been repeatedly shown ---
of solving these problems.

Most problems in Bayesian inference involve solving a marginalization integral of
the form
\begin{equation}
    \eqlabel{marginalization}
    p (\mathbf{X} | \boldsymbol{\Theta}) = \int
        p (\mathbf{X} | \boldsymbol{\Theta},\boldsymbol{\alpha}) \,
        p (\boldsymbol{\alpha}) \, \dd \boldsymbol{\alpha}
\end{equation}
where $p (\mathbf{X} | \boldsymbol{\Theta})$ is the marginalized likelihood of the
data $\mathbf{X}$ given the model parameters $\boldsymbol{\Theta}$. The integral in
\eq{marginalization} is over a set of \emph{nuisance parameters} $\boldsymbol{\alpha}$
that are (generally) of no physical interest in the problem. In some very specific
cases, this integral is analytically tractable but in general, the likelihood function
$p (\mathbf{X} | \boldsymbol{\Theta},\boldsymbol{\alpha})$ is not a simple analytically
integrable function. In fact, in many problems, the likelihood function is actually
the result of an extremely expensive numerical simulation. In this regime, the
marginalization is generally performed using Markov chain Monte Carlo (MCMC).
If the likelihood function is expensive to calculate, it is advantageous to use a
sampling algorithm that reduces the necessary number of likelihood evaluations.
This also precludes the use of second order methods (such as hybrid/Hamiltonian
Monte Carlo) that require the calculation of (numerical) gradients of the likelihood
function.

Most uses of MCMC in the astrophysics literature are based on slight modifications
to the Metropolis-Hastings (M-H) method \citep[e.g.][]{MacKay:2003}. Each step in
a M-H chain is proposed using a multivariate Gaussian centered on the current
position of the chain. Since each term in the covariance matrix of this proposal
distribution is an unspecified parameter, this method has $D\,[D+1]/2$ tuning parameters
(where $D$ is the dimension of the parameter space).  To make matters worse, the
performance of this sampler is very sensitive to the optimality of these tuning
parameters and there is no fool-proof method for choosing the values correctly.
As a result, many heuristic methods have been developed to attempt to determine
the optimal parameters in a data-driven way \citep[e.g.][]{Gregory:2005,Dunkley:2005,Widrow:2008}.
Unfortunately, these methods all require ``burn-in'' phases where shorter Markov chains
are sampled and the results are used to tune the hyperparameters. This extra cost
is unacceptable when the likelihood calls are computationally heavy.

The problem with traditional sampling methods can be visualized by studying the
highly anisotropic density
\begin{equation}
    \eqlabel{anisotropic}
    p(\mathbf{x}) \propto \exp \left (-\frac{(x_1-x_2)^2}{2\,\epsilon} - \frac{(x_1+x_2)^2}{2} \right )
\end{equation}
which would be considered ``difficult'' by standard MCMC algorithms. \Eq{anisotropic}
can be transformed into the much easier problem of sampling an isotropic Gaussian
by an \emph{affine transformation} of the form
\begin{equation}
    y_1 = \frac{x_1-x_2}{\sqrt{\epsilon}} \, , \,\,\, y_2 = x_1 + x_2.
\end{equation}
Therefore, an algorithm that is \emph{affine invariant} will be insensitive to
covariances between parameters. An affine invariant algorithm is unaffected by
any transformation of the density of the form
\begin{equation}
    \mathbf{Y} = \mathbf{A}\, \mathbf{X} + \mathbf{b}.
\end{equation}

Extending earlier work by \citet{Christen:2007},
\citet{Goodman:2010} proposed an affine invariant sampling algorithm with only
one hyperparameter that can be tuned for performance. This algorithm has since
proved effective in many projects
\citep[e.g.][Foreman-Mackey \& Widrow~2012, in prep.]{Hou:2011, Lang:2011}.

In this paper, I parallelize the algorithm so that any problem can generically
take advantage of this optimization. I also generalize the algorithm to allow
\emph{any} probabilistic unsupervised learning techniques to be used to inform
the proposal distribution.

\section{The Algorithm}

\subsection{The stretch move}

\citet{Goodman:2010} proposed an affine invariant ensemble sampling algorithm
informally called the ``stretch move''. This method involves simultaneously
evolving an ensemble of $K$ \emph{walkers} where the proposal distribution for one
walker $k$ is based on the current positions of the $K-1$ walkers in the
\emph{complementary ensemble}.

In practice, to update the position of a walker at position $\mathbf{X}_k$,
another walker $\mathbf{X}_j$ with $j \ne k$ is randomly chosen and then
a new position is proposed:
\begin{equation}
    \eqlabel{proposal}
    \mathbf{X}_k (t) \rightarrow \mathbf{Y} = \mathbf{X}_j + Z \, [\mathbf{X}_k (t) - \mathbf{X}_j]
\end{equation}
where $Z$ is a random variable drawn from a distribution $g(z)$.  It is clear that
if $g(z)$ satisfies
\begin{equation}
    g(z^{-1}) = z \, g(z),
\end{equation}
the proposal of \eq{proposal} is symmetric. In this case, the chain will satisfy
detailed balance if the proposal is accepted with probability
\begin{equation}
    \min \left \{ 1, Z^{n-1} \, \frac{p(\mathbf{Y})}{p(\mathbf{X}_k(t))} \right \}.
\end{equation}
This procedure is then repeated for each walker in the ensemble \emph{in series}.

\citet{Goodman:2010} advocate for a particular form of $g(z)$, namely
\begin{equation}
    g(z) \propto \left \{ \begin{array}{ll}
        \displaystyle\frac{1}{\sqrt{z}} & \mathrm{if}\, z\in \left [ \displaystyle\frac{1}{a}, a \right ], \\
        0 & \mathrm{otherwise}
    \end{array} \right .
\end{equation}
where $a$ is an adjustable scale parameter. For comparison, I will also use this
distribution with $a=2$ for all benchmarks in this paper.

\subsection{The parallel stretch move}

It is tempting to na\"ively parallelize the stretch move algorithm by simultaneously
advancing each walker based on the state of the ensemble instead of evolving the
walkers in series. Unfortunately, this would no longer satisfy detailed balance.
Instead, if we split the ensemble into two ensembles (labeled \emph{blue} and
\emph{red} for convenience) and simultaneously update all the blue walkers ---
using the stretch move procedure --- based on the positions of \emph{only the red
walkers} then the outcome is a valid step for each of the walkers. Then,
the red walkers are advanced based only on the positions in the blue ensemble.

The performance of this method --- quantified by the autocorrelation time --- is
comparable to the traditional stretch move algorithm but the fact that one can now
take advantage of generic parallelization makes this generalization extremely
powerful.

\subsection{Using machine learning to generate a better proposal distribution}

The proposal distribution given by \eq{proposal} can be visualized as fitting a
multi-dimensional Gaussian to the positions in the complementary ensemble,
doubling the eigenvalues of the covariance tensor and resampling from that
distribution. In fact, as one would expect, this scheme gives slightly better
performance when sampling from a multi-dimensional, highly covariant Gaussian
(described below). This realization makes it interesting to explore the possibility
of using more sophisticated machine learning techniques to provide a better proposal
distribution.

\subsubsection{The single Gaussian proposal}

The simplest extension is (as mentioned above) the single Gaussian proposal. Given
two ensembles $E_\mathrm{red} = \{ \mathbf{X}_1, \mathbf{X}_2, \ldots, \mathbf{X}_{K/2} \}$
and $E_\mathrm{blue} = \{ \mathbf{X}_{K/2+1}, \ldots, \mathbf{X}_{K} \}$, a single step
in the chain will involve:
\begin{enumerate}
    \item{
        Calculate the mean position $\bar{\mathbf{X}}_\mathrm{blue} = \frac{2}{K}\sum_{k=K/2+1} ^K \mathbf{X}_k$
        and covariance tensor $\mathcal{C}_\mathrm{blue}$ for the \emph{blue} walkers.
        }
    \item{
        Sample $K/2$ random vectors $\mathbf{Y}_k$ from the multivariate Gaussian distribution
        \begin{equation}
            \eqlabel{singlegaussprop}
            f(\mathbf{y}) = [2 \pi]^{-K/4} \left | \mathcal{C} \right |^{-1/2}
            \exp \left ( -\frac{1}{2} [\mathbf{y} - \bar{\mathbf{X}}_\mathrm{blue}]^\mathrm{T}
            \mathcal{C}^{-1} [\mathbf{y} - \bar{\mathbf{X}}_\mathrm{blue}] \right )
        \end{equation}
        }
    \item{
        Accept each proposed position with the probability
        \begin{equation}
            \eqlabel{singlegaussaccept}
            \min \left \{ 1, \frac{f(\mathbf{X}_k(t)) \, p(\mathbf{Y}_k)}{f(\mathbf{Y}_k) \, p(\mathbf{X}_k(t))} \right \}
        \end{equation}
        and set the positions of the \emph{red} walkers to either $\mathbf{X}_k (t+1) = \mathbf{X}_k(t)$
        if the proposal is rejected
        or $\mathbf{X}_k (t+1) = \mathbf{Y}_k$ if the step is accepted.
        }
    \item{
        Repeat steps 1-3 with the red and blue ensembles switched.
        }
\end{enumerate}

\subsubsection{The mixture of Gaussians proposal}

\Eq{singlegaussprop} above can be replaced by a mixture of Gaussians and it can
be trained using EM or a similar algorithm. In this case, the algorithm is
as follows:
\begin{enumerate}
    \item{
        Run K-means (with $K=M$ is a free parameter of the sampler) on the blue
        walkers to initialize the EM algorithm, run EM
        to convergence (or stop early as discussed later) to find the amplitudes
        $\alpha_j$, the means $\boldsymbol{\mu}_j$ and covariances $\Sigma_j$ of the Gaussians.
        }
    \item{
        Sample $K/2$ vectors from
        \begin{equation}
            f(\mathbf{y}) = [2 \pi]^{-K/4} \sum _{j=1} ^{M} \alpha_j \, \left | \Sigma_j \right |^{-1/2} \,
            \exp \left ( -\frac{1}{2} [\mathbf{y} - \boldsymbol{\mu}_j]^\mathrm{T}
            \Sigma_j^{-1} [\mathbf{y} - \boldsymbol{\mu}_j] \right )
        \end{equation}
        }
    \item{
        Accept the proposed positions with the probability given by \eq{singlegaussaccept}.
        }
\end{enumerate}

The major problem with this algorithm is that the K-means algorithm is not affine
invariant.  Instead, I generalized the K-means algorithm to work with any arbitrary
metric (not just Euclidean).  If the covariance tensor of the samples is used as
the metric then the algorithm is affine invariant.  I will study the performance of
both of these algorithms below.

\subsubsection{The mixture of Laplacians proposal}

I did not implement the mixture of Laplacians proposal distribution for this paper
but it should be a simple extension of the mixture of Gaussians model. Laplacians
are advantageous because they have ``heavier tails''. This will improve the sampling
performance in the tails of the target density. The mixture of Gaussians has very weak
support in the tails so walkers tend to get ``stuck'' in the tails of the distribution.

\section{Benchmarks \& Tests}

\subsection{Measuring the performance}

A standard method of quantifying the performance of an MCMC sampler is to estimate
the autocorrelation time of the sampler on several densities.

The main goal of running a Markov chain is to measure the expectation value (and
variance) of a particular value (e.g.~$f$)
\begin{equation}
    \left < f(\mathbf{x}) \right > = \int f(\mathbf{x}) \, p (\mathbf{x}) \, \dd \mathbf{x}
\end{equation}
which can be approximated as
\begin{equation}
    \eqlabel{schainestim}
    \left < f(\mathbf{x}) \right > \approx \frac{1}{T_s} \sum_{t=1}^{T_s} f(\mathbf{X}(t))
\end{equation}
where $T$ is the length of the chain.  The generalization of \eq{schainestim} to
the case of the ensemble sampler is
\begin{equation}
    \eqlabel{echainestim}
    \left < f(\mathbf{x}) \right > \approx \frac{1}{T_e} \sum_{t=1}^{T_s} \left [ \frac{1}{K} \sum_{k = 1}^{K} f(\mathbf{X}_k(t)) \right ]
\end{equation}
where $K$ is the number of walkers.  The autocorrelation function of the chain is
then given by
\begin{equation}
    C (t) = \frac{1}{K^2} \lim_{t^\prime \to \infty} \mathrm{cov} \left [ \sum_{k = 1}^{K} f(\mathbf{X}_k (t+t^\prime)),
         \sum_{k = 1}^{K} f(\mathbf{X}_k (t^\prime)) \right ]
\end{equation}
and the integrated autocorrelation time is given by
\begin{equation}
    \tau = \sum_{t= -\infty} ^{\infty} \frac{C(t)}{C(0)} .
\end{equation}

For all tests discussed in this paper, I have used the \project{pyacor}\footnote{\texttt{https://github.com/dfm/acor}}
module to estimate the autocorrelation time of the chains. I ported \project{pyacor} to \project{Python}
from the original \project{C++} procedure that is described in \citet{Goodman:2010} and
is available online\footnote{\texttt{http://www.math.nyu.edu/faculty/goodman/software/acor/index.html}}.


\subsection{Multivariate Gaussian distribution}

The simplest test of an MCMC sampler is its sampling performance on a highly covariant
multivariate Gaussian density. For the tests in the paper, I randomly generated
a 50 dimensional positive definite covariance tensor and initial conditions for each
walker.  Then, each sampler was tested with the same initial conditions for its
performance on the density
\begin{equation}
    \pi (\mathbf{x}) \propto \exp\left ( -\frac{1}{2} \mathbf{x}^T \, \Sigma^{-1} \, \mathbf{x} \right )
\end{equation}
for the same covariance tensor $\Sigma$ in each trial.

I ran a chain with $10^3$ steps and 100 walkers to measure the performance of the
samplers on this density. For comparison, I also tested a basic M-H sampler. For
the mixture-of-Gaussian (MOG) models, I used $K = 1$ Gaussians. The
results are shown in \tab{gaussian}. As expected, the stretch move performs
significantly better than M-H and the single Gaussian proposal is slightly better
than that. Since EM with a single Gaussian finds the maximum likelihood solution
for the mean and variance, it is unsurprising that the performance is identical
to the analytic single Gaussian case.

\subsection{The Rosenbrock density}

The Rosenbrock density
\begin{equation}
    p(\mathbf{x}) \propto \exp \left ( -\frac{100 \, (x_2 - x_1^2)^2+ (1-x_1)^2}{20} \right )
\end{equation}
is plotted in \fig{rosenbrock}. Despite the fact that it is only two-dimensional,
this density poses severe problems for all MCMC samplers.

I ran a chain with $10^3$ steps and 100 walkers to test the performance
of the samplers on this difficult density. The performance statistics in this
case are similar to the results for the Gaussian with the extensions presented in
this paper performing somewhat better than the stretch move algorithm.

\section{Implementation Details}

The core module is implemented in the \project{Python} files in the \texttt{pyest}
directory. The abstract \texttt{Sampler} object definition is found in
\texttt{pyest/sampler.py}. A simple vanilla M-H sampler is found in \texttt{pyest/mh.py}.
The original stretch move sampler is implemented in the \texttt{EnsembleSampler}
object in \texttt{pyest/ensemble.py} as well as the skeleton for the parallelized
and generalized samplers in the \texttt{DualEnsembleSampler} object. The
mixture-of-Gaussians ensembles are implemented in \texttt{pyest/mog.py} module.
The mixture models depend on the mixture module in the \texttt{pyest/mixtures}
directory. This is modified version of the code that I wrote for the third
homework assignment in this class. All of the samplers depend on a custom version
of the \project{pyacor} module that can be found in the \texttt{pyest/acor} directory.

Before usage, the module must be built and installed by running \texttt{make}
in the root directory of the module. Then, a suite of unit tests for all the
samplers can be run as

\texttt{python pyest/tests.py}

\noindent or using \texttt{nosetests}.

The experiments described in the previous section can be repeated by running

\texttt{python experiments.py}

\noindent The command line arguments to modify the experiments are described in
the help that can be retrieved with the \texttt{--help} flag.

\begin{thebibliography}{70}
\raggedright

\bibitem[Christen~(2007)]{Christen:2007}
{Christen}, J., \emph{A general purpose scale-independent MCMC algorithm}, technical report I-07-16,
CIMAT, Guanajuato, 2007.

\bibitem[Dunkley \etal(2005)]{Dunkley:2005}
{Dunkley}, J., {Bucher}, M., {Ferreira}, P.~G., {Moodley}, K., \& {Skordis}, C.,
2005, \mnras, 356, 925-936
% http://adsabs.harvard.edu/abs/2005MNRAS.356..925D

\bibitem[Goodman \& Weare~(2010)]{Goodman:2010}
Goodman,~J., \& Weare,~J.,
2010, Comm.\ App.\ Math.\ Comp.\ Sci., 5, 65

\bibitem[Gregory~(2005))]{Gregory:2005}
{Gregory}, P.~C., \emph{Bayesian Logical Data Analysis for the Physical Sciences},
Cambridge University Press, 2005
% http://adsabs.harvard.edu/abs/2005blda.book.....G

\bibitem[Hou \etal(2011))]{Hou:2011}
{Hou}, F., {Goodman}, J., {Hogg}, D.~W., {Weare}, J., \& {Schwab}, C.,
2011, arXiv:1104.2612
% http://adsabs.harvard.edu/abs/2011arXiv1104.2612H

\bibitem[Lang \& Hogg (2011))]{Lang:2011}
{Lang}, D. and {Hogg}, D.~W.,
2011, arXiv:1103.6038
% http://adsabs.harvard.edu/abs/2011arXiv1103.6038L

\bibitem[MacKay~(2003))]{MacKay:2003}
{MacKay}, D., \emph{Information Theory, Inference, and Learning Algorithms},
Cambridge University Press, 2003

\bibitem[Widrow \etal(2008))]{Widrow:2008}
{Widrow}, L.~M. and {Pym}, B. and {Dubinski}, J.,
2008, \apj, 679, 1239
% http://adsabs.harvard.edu/abs/2008ApJ...679.1239W

\end{thebibliography}

\clearpage


\begin{deluxetable}{cc}
    \tablecaption{Benchmark results for the Gaussian density \tablabel{gaussian}}
    \tablewidth{0pt}
    \tablehead{
    \colhead{Sampler} & \colhead{Average autocorrelation time}
    }
    \startdata

        Metropolis-Hastings & 140.67 \\
        Stretch move & 0.95 \\
        Single Gaussian proposal & 0.68 \\
        Mixture-of-Gaussians proposal & 0.75 \\
        Affine invariant MOG proposal & 0.75 \\

    \enddata
\end{deluxetable}


\begin{figure}
\epsscale{1.}
\plotone{rosenbrock.pdf}
\caption{The Rosenbrock density.\figlabel{rosenbrock}}
\end{figure}

\begin{deluxetable}{ccc}
    \tablecaption{Benchmark results for the Rosenbrock density \tablabel{rosenbrock}}
    \tablewidth{0pt}
    \tablehead{
    \colhead{Sampler} & \colhead{$\mathrm{Acor}(x_1)$} & \colhead{$\mathrm{Acor}(x_2)$}
    }
    \startdata

        Metropolis-Hastings & 503.69 & 115.08 \\
        Stretch move & 1.45 & 0.69 \\
        Single Gaussian proposal & 0.76 & 0.06 \\
        Mixture-of-Gaussians proposal & 0.66 & 0.49 \\
        Affine invariant MOG proposal & 0.91 & 0.98 \\

    \enddata
\end{deluxetable}

\end{document}


